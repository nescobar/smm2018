{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in c:\\users\\jay\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: future in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests-oauthlib->python-twitter)\n"
     ]
    }
   ],
   "source": [
    "#Install packages\n",
    "\n",
    "!pip install python-twitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import twitter\n",
    "import html\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key = 'FP94BfUftKeygulmcLcVqRNvX',\n",
    "                 consumer_secret = 'GfZtNuk6Zu6lTOYGWibXI95MjMyks6SSlBEykyLuYe4NEUgGUu',\n",
    "                 access_token_key = '961088185756393472-FopLzpw7n3CrHhbHoWv8BlnR1mZwhGH',\n",
    "                 access_token_secret= '62Trp0LVEPvAwoGPH4ov8D4TQe2eEaQETKIfXKCPZX6NN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Wed Feb 07 04:04:14 +0000 2018\", \"default_profile\": true, \"default_profile_image\": true, \"id\": 961088185756393472, \"lang\": \"en\", \"name\": \"IUSMM2018\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"iusmm2018\"}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: 86 tweets with the term %23HurricaneHarvey%20OR%20%23Harvey!!\n"
     ]
    }
   ],
   "source": [
    "# create function to accept search term and tehn fetch the tweets for that term\n",
    "\n",
    "def TestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched = api.GetSearch(search_string, count=100)\n",
    "        print(\"Fetched: \"+str(len(tweets_fetched))+\" tweets with the term \"+search_string+\"!!\")\n",
    "        return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]        \n",
    "    except:\n",
    "        print(\"fetch_error: please check\")\n",
    "        return None\n",
    "              \n",
    "\n",
    "testData = TestData(\"%23HurricaneHarvey%20OR%20%23Harvey\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': None,\n",
       "  'text': 'Born and raised in Houston and plays for @astrosbaseball Michael Bourn did his #MillionDollarPledge #10for10â€¦ https://t.co/mA9j1QKcde'},\n",
       " {'label': None,\n",
       "  'text': \"On Oct. 30, 2017, George P. Bush's agency signed a $13.47 million contract with Horne LLP for #Harvey disaster recoâ€¦ https://t.co/c1EyOjTVbM\"},\n",
       " {'label': None,\n",
       "  'text': 'What would it take to set up 10,000 cots overnight? An army of #volunteers and an organization like @BakerRipley toâ€¦ https://t.co/X6lfBjSCxI'},\n",
       " {'label': None,\n",
       "  'text': 'Join 8 people right now at \"Harvey Weinstein\\'s lawyer says mogul\\'s behavior had \\'no criminality\\'\" #cheersâ€¦ https://t.co/jVf0MSxQ2c'},\n",
       " {'label': None,\n",
       "  'text': \"#Harvey Weinstein's #Lawyer says ...  \\nMore here : https://t.co/PVNOJHSkvG  'no #Criminality039 #Mogul039sâ€¦ https://t.co/bnhmTH2Vcv\"},\n",
       " {'label': None,\n",
       "  'text': 'RT @DonnaWR8: .@POTUS #TRUMPðŸ‡ºðŸ‡¸ &amp; @FLOTUSðŸŒº\\n\\nWhen ALL seemed HOPELESS...YOU brought HOPE!\\n\\nYou INSPIRE us ALL!\\n\\n#MAGA #Harvey @Scavino45 #USAâ€¦'},\n",
       " {'label': None,\n",
       "  'text': 'RT @jmb063: Too many signs in the heavens &amp; on the earth to just be a coincidence! Seek #Truth! #Revelation12 #September23 #Eclipse #Harveyâ€¦'},\n",
       " {'label': None,\n",
       "  'text': '#Harvey lingers for businesses in my neighborhood. #Catmull https://t.co/9J1HJoRWRO'},\n",
       " {'label': None,\n",
       "  'text': '@notrobertdeniro No your the mistake. You molester go hide away somewhere like your good friends #HARVEY Andâ€¦ https://t.co/2ruC2EFm3j'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2:  To manually annotate the downloaded tweets based on relief terms in the tweets and/or write a function to create a corpus to use as training data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nescobar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nescobar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Step 3:  Pre-process the Tweets\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords=set(stopwords.words('english')+list(punctuation)+['ATUSER','URL','IMG'])\n",
    "        \n",
    "    def processTweets(self,list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"])))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self,tweet):\n",
    "        # Unescape from HTML\n",
    "        tweet = html.unescape(tweet)\n",
    "        # 3a. Convert to lower case\n",
    "        tweet = tweet.lower()\n",
    "        # 3b. Replace links with the word URL \n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet) \n",
    "        # 3c. Replace @username with \"AT_USER\"\n",
    "        tweet = re.sub('@[^\\s]+','ATUSER',tweet)\n",
    "        # 3d. Replace #word with word \n",
    "        tweet = re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "        # 3e. Replace images with the word IMG \n",
    "        tweet = re.sub(r'\\bpic.twitter.com\\s+', 'IMG', tweet)\n",
    "        # 3f Keep only words with letters\n",
    "        tweet = re.sub('[^a-zA-Z]',' ',tweet)\n",
    "        # 3g. Remove RT\n",
    "        tweet = re.sub(r'\\brt([\\b\\s])', '', tweet)\n",
    "        # 3h. tokenize tweets\n",
    "        tweet = word_tokenize(tweet)\n",
    "        # Apply stemming\n",
    "        # stemmer = SnowballStemmer(\"english\")\n",
    "        # Apply Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word) for word in tweet if word not in self._stopwords]\n",
    "    \n",
    "tweetProcessor=PreProcessTweets()\n",
    "#ppTrainingData=tweetProcessor.processTweets(trainingData)\n",
    "ppTestData=tweetProcessor.processTweets(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['born', 'raised', 'houston', 'play', 'michael', 'bourn', 'milliondollarpledge'], ['oct', 'george', 'p', 'bush', 'agency', 'signed', 'million', 'contract', 'horne', 'llp', 'harvey', 'disaster', 'reco'], ['would', 'take', 'set', 'cot', 'overnight', 'army', 'volunteer', 'organization', 'like'], ['join', 'people', 'right', 'harvey', 'weinstein', 'lawyer', 'say', 'mogul', 'behavior', 'criminality', 'cheer'], ['harvey', 'weinstein', 'lawyer', 'say', 'criminality', 'mogul'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['many', 'sign', 'heaven', 'earth', 'coincidence', 'seek', 'truth', 'revelation', 'september', 'eclipse', 'harvey'], ['harvey', 'lingers', 'business', 'neighborhood', 'catmull'], ['mistake', 'molester', 'go', 'hide', 'away', 'somewhere', 'like', 'good', 'friend', 'harvey'], ['new', 'york', 'sue', 'weinstein', 'co', 'harvey', 'weinstein', 'sexu'], ['almost', 'month', 'since', 'hurricaneharvey', 'hit', 'devastated', 'houston', 'time', 'past', 'forgotten'], ['people', 'getting', 'insurance', 'check', 'went', 'houston', 'rv', 'show', 'today', 'found', 'harvey', 'victim'], ['great', 'see', 'american', 'company', 'help', 'time', 'need', 'know', 'helped', 'distribute', 'water', 'durin'], ['people', 'getting', 'insurance', 'check', 'went', 'houston', 'rv', 'show', 'today', 'found', 'harvey', 'victim'], ['people', 'getting', 'insurance', 'check', 'went', 'houston', 'rv', 'show', 'today', 'found', 'harvey', 'victim'], ['interesting', 'think', 'fema', 'altered', 'response', 'based', 'backlash', 'previous', 'disaster', 'response', 'wo'], ['people', 'getting', 'insurance', 'check', 'went', 'houston', 'rv', 'show', 'today', 'found', 'harvey'], ['hurricane', 'harvey', 'tropical', 'cyclone', 'report', 'released', 'full', 'document'], ['harvey', 'weinstein', 'forced', 'staff', 'manage', 'conquest'], ['alright', 'month', 'sweat', 'tear', 'finally', 'say', 'house', 'done', 'hurricaneharvey', 'houstonstrong', 'ht'], ['alright', 'month', 'sweat', 'tear', 'finally', 'say', 'house', 'done', 'hurricaneharvey', 'houstonstrong', 'ht'], ['alright', 'month', 'sweat', 'tear', 'finally', 'say', 'house', 'done', 'hurricaneharvey'], ['purchase', 'book', 'help', 'raise', 'fund', 'harvey', 'irma', 'maria', 'relief', 'catholic'], ['ny', 'attorney', 'general', 'sue', 'weinstein', 'company', 'harvey', 'wein'], ['failed', 'two', 'important', 'area', 'protecting', 'alamo', 'responding', 'hurricaneharvey', 'enough', 'enou'], ['see', 'sun', 'houston', 'harvey', 'houstonstrong', 'houstonflood', 'hurricaneharvey'], ['glad', 'latest', 'government', 'shutdown', 'bill', 'page', 'good', 'part', 'funding', 'hurricaneharvey', 'r'], ['ny', 'attorney', 'general', 'sue', 'weinstein', 'company', 'harvey'], ['harvey', 'weinstein', 'twc', 'sued', 'n', 'attorney', 'general', 'civil', 'right', 'violation', 'harvey', 'weinstein', 'twc'], ['go', 'katie', 'well', 'done', 'lass', 'harvey'], ['hi', 'austin', 'help', 'get', 'wag', 'adopted', 'little', 'guy', 'hurricaneharvey', 'rescue'], ['kid', 'teen', 'affected', 'hurricane', 'harvey', 'happy', 'tapping', 'mia', 'charlie', 'energy', 'eft', 'teena'], ['musicfamily', 'timeisnow', 'comintogether', 'workininunison', 'shatteredlives', 'journeytonorm', 'info', 'hurricaneharvey'], ['interesting', 'read', 'hurricane', 'harvey', 'observation', 'improving', 'hospital', 'disaster', 'response'], ['musicfamily', 'timeisnow', 'comintogether', 'workininunison', 'shatteredlives', 'journeytonorm', 'info', 'hurricaneharvey'], ['help', 'u', 'provide', 'diaper', 'friend', 'houston', 'austin', 'hurricaneharvey'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['news', 'housing', 'industry', 'gear', 'face', 'hurricane', 'harvey', 'ht', 'like', 'follow', 'socaltelevision'], ['musicfamily', 'timeisnow', 'comintogether', 'workininunison', 'shatteredlives', 'journeytonorm', 'info', 'hurricaneharvey'], ['musicfamily', 'timeisnow', 'comintogether', 'workininunison', 'shatteredlives', 'journeytonorm', 'info', 'hurricaneharvey'], ['donate', 'loved', 'one', 'body', 'science', 'unless', 'want', 'end', 'freighter', 'china', 'many'], ['life', 'pro', 'tip', 'go', 'harvey', 'tell', 'ur', 'harvey', 'instant', 'discount', 'harvey'], ['good', 'article', 'disaster', 'relief', 'clinic', 'semester', 'thomasfire', 'hurricaneharvey'], ['good', 'article', 'disaster', 'relief', 'clinic', 'semester', 'thomasfire', 'hurricaneharvey'], ['helping', 'community', 'rebuild', 'stronger', 'hurricaneharvey', 'another', 'top', 'focus', 'bruun', 'said', 'experience', 'wi'], ['harvey'], ['read', 'progress', 'toward', 'hurricaneharvey', 'recovery', 'update', 'h'], ['txlege', 'txpolitics', 'six', 'month', 'harvey', 'state', 'leader', 'aided', 'federal', 'largess', 'eyeing', 'ikedike'], ['devastation', 'left', 'hurricaneharvey', 'community', 'turning', 'resilient', 'construction', 'standa'], ['devastation', 'left', 'hurricaneharvey', 'community', 'turning', 'resilient', 'construction', 'standa'], ['grainger', 'rethink', 'chemical', 'storage', 'following', 'hurricaneharvey'], ['rethink', 'chemical', 'storage', 'following', 'hurricaneharvey'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['texas', 'flood', 'researcher', 'compare', 'pollution', 'level', 'hurricaneharvey', 'environmenta'], ['bit', 'art', 'pixel', 'lowres', 'bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw'], ['thank', 'harvey', 'brazoriacounty'], ['served', 'congress', 'regularly', 'voted', 'federal', 'disaster', 'aid', 'district', 'th'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['baylor', 'university', 'mission', 'sends', 'springbreak', 'relief', 'team', 'area', 'damaged', 'hurricaneharvey'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['bit', 'art', 'pixel', 'lowres', 'bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['bit', 'art', 'pixel', 'lowres', 'bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw'], ['bit', 'art', 'pixel', 'lowres', 'bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle'], ['buying', 'selling', 'vehicle', 'vital', 'know', 'titletransfer', 'process', 'entail', 'abc', 'title'], ['harvey', 'affected', 'county', 'visit', 'lobby', 'defending', 'economic', 'growth'], ['forgotten', 'hurricaneharvey', 'long', 'path', 'recovery', 'guardian'], ['failed', 'two', 'important', 'area', 'protecting', 'alamo', 'responding', 'hurricaneharvey', 'enough', 'enou'], ['trump', 'seemed', 'hopeless', 'brought', 'hope', 'inspire', 'u', 'maga', 'harvey', 'usa'], ['struggle', 'continue', 'victim', 'hurricaneharvey', 'provide', 'aide', 'donate'], ['boulderco', 'adopt', 'arlo', 'came', 'hurricaneharvey', 'land'], ['global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rain', 'three', 'time', 'likely', 'research', 'reveals'], ['hurricaneharvey', 'update'], ['announces', 'greater', 'houston', 'area', 'winner', 'ford', 'freedom', 'unsung', 'hero', 'harvey', 'award', 'csr'], ['evil', 'forgotten', 'hurricaneharvey', 'long', 'path', 'recovery', 'kept', 'virtually', 'impassable'], ['iwillneverunderstand', 'quickly', 'power', 'forget', 'fellow', 'american', 'need'], ['failed', 'two', 'important', 'area', 'protecting', 'alamo', 'responding', 'hurricaneharvey', 'enough', 'enou'], ['musicfamily', 'timeisnow', 'comintogether', 'workininunison', 'shatteredlives', 'journeytonorm', 'info', 'hurricaneharvey']]\n"
     ]
    }
   ],
   "source": [
    "print(ppTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Extract features from both training and test data using multinomial Naive Bayes Classifier\n",
    "\n",
    "#Step 4a : Build a Vocabulary\n",
    "\n",
    "#Step 4b : Represent each tweet with presence/absence of the relief terms in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Train the classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6 : Use the classifier to classify the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 7 : Model Inference & Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
