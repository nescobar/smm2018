{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in c:\\users\\jay\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: requests in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: future in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\jay\\anaconda3\\lib\\site-packages (from python-twitter)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in c:\\users\\jay\\anaconda3\\lib\\site-packages (from requests-oauthlib->python-twitter)\n"
     ]
    }
   ],
   "source": [
    "#Install packages\n",
    "\n",
    "!pip install python-twitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api = twitter.Api(consumer_key = 'FP94BfUftKeygulmcLcVqRNvX',\n",
    "                 consumer_secret = 'GfZtNuk6Zu6lTOYGWibXI95MjMyks6SSlBEykyLuYe4NEUgGUu',\n",
    "                 access_token_key = '961088185756393472-FopLzpw7n3CrHhbHoWv8BlnR1mZwhGH',\n",
    "                 access_token_secret= '62Trp0LVEPvAwoGPH4ov8D4TQe2eEaQETKIfXKCPZX6NN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Wed Feb 07 04:04:14 +0000 2018\", \"default_profile\": true, \"default_profile_image\": true, \"id\": 961088185756393472, \"lang\": \"en\", \"name\": \"IUSMM2018\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"screen_name\": \"iusmm2018\"}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: 100 tweets with the term #Harvey!!\n"
     ]
    }
   ],
   "source": [
    "# create function to accept search term and tehn fetch the tweets for that term\n",
    "\n",
    "def TestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched = api.GetSearch(search_string, count=100)\n",
    "        print(\"Fetched: \"+str(len(tweets_fetched))+\" tweets with the term \"+search_string+\"!!\")\n",
    "        return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]        \n",
    "    except:\n",
    "        print(\"fetch_error: please check\")\n",
    "        return None\n",
    "              \n",
    "\n",
    "testData = TestData(\"#Harvey\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': None,\n",
       "  'text': \"On Oct. 30, 2017, George P. Bush's agency signed a $13.47 million contract with Horne LLP for #Harvey disaster reco… https://t.co/c1EyOjTVbM\"},\n",
       " {'label': None,\n",
       "  'text': \"11K+ volunteers have worked w/@SamaritansPurse in TX since the hurricane! I'm thankful for them &amp; the encouragement… https://t.co/8zRGTO6mUJ\"},\n",
       " {'label': None,\n",
       "  'text': \"In Houston, thousands of #Harvey victims are still waiting for aid to repair their homes. Here's the story of one f… https://t.co/1D8THAv98K\"},\n",
       " {'label': None,\n",
       "  'text': 'RT @TheGabHarvey: #8bit #art #pixel #lowres #8bitart #pixelart #grandpa #punk #gab #harvey #white #hair #gabharvey #notafraid #doodle #draw…'},\n",
       " {'label': None, 'text': '. to thank you! #harvey #brazoriacounty'},\n",
       " {'label': None,\n",
       "  'text': 'RT @DonnaWR8: .@POTUS #TRUMP🇺🇸 &amp; @FLOTUS🌺\\n\\nWhen ALL seemed HOPELESS...YOU brought HOPE!\\n\\nYou INSPIRE us ALL!\\n\\n#MAGA #Harvey @Scavino45 #USA…'},\n",
       " {'label': None,\n",
       "  'text': 'RT @DonnaWR8: .@POTUS #TRUMP🇺🇸 &amp; @FLOTUS🌺\\n\\nWhen ALL seemed HOPELESS...YOU brought HOPE!\\n\\nYou INSPIRE us ALL!\\n\\n#MAGA #Harvey @Scavino45 #USA…'},\n",
       " {'label': None,\n",
       "  'text': 'RT @DonnaWR8: .@POTUS #TRUMP🇺🇸 &amp; @FLOTUS🌺\\n\\nWhen ALL seemed HOPELESS...YOU brought HOPE!\\n\\nYou INSPIRE us ALL!\\n\\n#MAGA #Harvey @Scavino45 #USA…'},\n",
       " {'label': None,\n",
       "  'text': 'RT @DonnaWR8: .@POTUS #TRUMP🇺🇸 &amp; @FLOTUS🌺\\n\\nWhen ALL seemed HOPELESS...YOU brought HOPE!\\n\\nYou INSPIRE us ALL!\\n\\n#MAGA #Harvey @Scavino45 #USA…'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2:  To manually annotate the downloaded tweets based on relief terms in the tweets and/or write a function to create a corpus to use as training data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Jay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Step 3:  Pre-process the Tweets\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords=set(stopwords.words('english')+list(punctuation)+['AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self,list_of_tweets):\n",
    "        processedTweets=[]\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"])))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self,tweet):\n",
    "        # 3a. Convert to lower case\n",
    "        tweet=tweet.lower()\n",
    "        # 3b. Replace links with the word URL \n",
    "        tweet=re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)     \n",
    "        # 3c. Replace @username with \"AT_USER\"\n",
    "        tweet=re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "        # 3d. Replace #word with word \n",
    "        tweet=re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "        #3e. tokenize tweets\n",
    "        tweet=word_tokenize(tweet)\n",
    "        return [word for word in tweet if word not in self._stopwords]\n",
    "    \n",
    "tweetProcessor=PreProcessTweets()\n",
    "#ppTrainingData=tweetProcessor.processTweets(trainingData)\n",
    "ppTestData=tweetProcessor.processTweets(testData)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['oct.', '30', '2017', 'george', 'p.', 'bush', \"'s\", 'agency', 'signed', '13.47', 'million', 'contract', 'horne', 'llp', 'harvey', 'disaster', 'reco…'], ['11k+', 'volunteers', 'worked', 'w/AT_USER', 'tx', 'since', 'hurricane', \"'m\", 'thankful', 'amp', 'encouragement…'], ['houston', 'thousands', 'harvey', 'victims', 'still', 'waiting', 'aid', 'repair', 'homes', \"'s\", 'story', 'one', 'f…'], ['rt', '8bit', 'art', 'pixel', 'lowres', '8bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw…'], ['thank', 'harvey', 'brazoriacounty'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '8bit', 'art', 'pixel', 'lowres', '8bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '8bit', 'art', 'pixel', 'lowres', '8bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle', 'draw…'], ['8bit', 'art', 'pixel', 'lowres', '8bitart', 'pixelart', 'grandpa', 'punk', 'gab', 'harvey', 'white', 'hair', 'gabharvey', 'notafraid', 'doodle…'], ['buying', 'selling', 'vehicle', \"'s\", 'vital', 'know', 'titletransfer', 'process', 'entails', 'abc', 'title', 'of…'], ['harvey-affected', 'county', 'visit', 'lobby', 'defending', 'economic', 'growth'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rains', 'three', 'times', 'likely', 'research', 'reveals'], ['.AT_USER', 'announces', 'greater', 'houston', 'area', 'winners', 'ford', 'freedom', 'unsung', 'heroes', 'harvey', 'awards', 'csr'], ['rt', 'global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rains', 'three', 'times', 'likely', 'research', 'reveals'], ['rt', 'global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rains', 'three', 'times', 'likely', 'research', 'reveals'], ['rt', 'global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rains', 'three', 'times', 'likely', 'research', 'reveals'], ['global', 'warming', 'made', 'hurricane', 'harvey', 'deadly', 'rains', 'three', 'times', 'likely', 'research', 'reveals'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'lot', 'risers', 'tx', 'right', 'thanks', 'putting', 'clip', 'together', 'donate', 'harvey', 'relief', '⇨'], ['would', 'take', 'set', '10,000', 'cots', 'overnight', 'army', 'volunteers', 'organization', 'like', 'to…'], ['rt', 'fear', 'may', 'become', 'frequent', 'occurrence', 'may', 'like', 'climatechange', 'harvey', 'theneedformorepeopletostudyeme…'], ['fear', 'may', 'become', 'frequent', 'occurrence', 'may', 'like', 'climatechange', 'harvey…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['guy', 'gropinjoebiden', 'creeper', 'harvey'], ['would', 'take', 'set', '10,000', 'cots', 'overnight', 'army', 'volunteers', 'organization', 'like', 'to…'], ['tried', 'watching', 'saturday', 'night', 'live', 'experts', 'calling', 'harvey', 'bad', 'joke', 'willing', 'to…'], ['yesterday', \"'s\", 'rainfall', 'houston', '2nd', 'daily', 'rainfall', 'since', 'hurricane', 'harvey', 'txwx', 'texas'], ['rt', 'following', 'harvey', 'weinstein', 'creep', 'predator', 'harveyweinstein', 'predator', 'rapist', 'harvey', 'doctorivan', 'holly…'], ['job', 'might', 'great', 'fit', 'load', 'puller', 'labor', 'harvey', 'la', 'hiring', 'careerarc'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'people', 'would', 'rather', 'starve', 'hurricane', 'buy', 'chicken', 'amp', 'waffles', 'flavored', 'harvey', 'hurricaneharvey', 'http…'], ['montgomery', 'county', 'says', '4000', 'homes', 'flooded', 'harvey', 'mostly', 'along', 'spring', 'creek', 'south', 'county', 'waterwa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['thank', 'blue', 'cross', 'amp', 'blue', 'shield', 'cmo', 'presented', 'coastal', 'bend', 'disaster', 'recovery', 'group', 'check', '500,000.…'], ['rt', '``', 'beauty', 'storm', \"''\", 'see', '``', 'big', 'c', 'church', 'showed', 'houston', 'harvey', 'church', 'unity', 'l…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['hollywood', 'elites', 'understand', 'opinions', 'reveal', 'double', 'standards', 'lives', '😂…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['illegal', 'patent', 'nature', 'weather', 'modification', 'patent', 'patent', 'holder', 'liable', 'harvey…'], ['flood', 'know', 'someone', 'support', 'harvey', 'victims', 'like'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['thank', 'posting', 'story', 'great', 'gabrielmachtfans', 'read', 'enjoy', 'story', 'suits', 'donna', 'harvey'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['come', 'harvey', 'harvey'], ['harvey', 'starting', 'troubles', '...', 'doesn’t', 'look', 'fresh', 'going', 'deeper', 'leading', 'group', 'pyeongchang2018', 'olympics', 'skiathlon'], ['niskanen', 'pacing', 'classic', 'part', '...', 'klaebo', 'harvey', 'sundby', 'holund', 'cologna', 'forms', 'leading', 'group', 'skiathlon', 'pyeongchang2018', 'olympics'], ['must', 'taking', 'lessons', '45', 'always', 'pledges', 'personal', 'donate', 'various', 'causes', 'hu…'], ['rt', 'irs', 'offers', 'safe', 'harbor', 'methods', 'determine', 'property', 'losses', 'may', 'especially', 'useful', 'victims', 'hurricanes', 'harvey', '…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['harvey', 'wake', 'type', 'super', 'germ', 'that’s', 'taking', 'folks', 'texas'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['perro', 'escapa', 'del', 'huracan', 'harvey', 'solo', 'con', 'su', 'bolsa', 'de', 'comida', 'mascotas', 'perro', 'harvey'], ['rt', 'following', 'harvey', 'weinstein', 'creep', 'predator', 'harveyweinstein', 'predator', 'rapist', 'harvey', 'doctorivan', 'holly…'], ['anybuddy', 'wan', 'na', 'partee', 'style', 'dogsoftwitter', 'harvey'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['obviously', 'food', '😂', 'weimaraner', 'weimaranersofinstagram', 'hessoproper', 'austrailianshepherd', 'labradorretriever…'], ['rt', '29', 'affected', 'residents', 'said', 'since', 'harvey', 'fallen', 'behind', 'rent', 'mortgage', 'avenue', 'provides', 'forecl…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'harvey', 'mayweathervmcgregor', 'jets', '🐶goodgame', 'labanpilipinas', 'fuck', 'power', 'missed', 'fight', 'endmylife', '…'], ['harveyweinstein', 'still', 'top', 'totem', 'pole', 'playing', 'amp', 'manipulating', 'women', 'attack', 'other…'], ['rt', 'kitty', 'flooded', 'harvey', 'cats', 'barely', 'rescued', 'please', 'help'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['trump', 'cuck', 'rt', 'rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'h…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'hope', 'everyone', 'enjoyed', 'harvey', 'favourite', 'memory', 'seeing', 'show'], ['spoke', 'friends', 'san', 'bernard', 'river', 'afternoon', 'harvey', 'great', 'group', 'folks', 'theshlife…'], ['thanks', 'carrier', 'make', 'speech', '10:00', 'a.m.', 'harvey'], ['sometimes', 'feel', 'like', \"'m\", 'westbanker', 'everybody', 'else', 'wan', 'na', 'across', 'river', 'nomtoc', 'algiers', 'harvey', 'marrero', 'stand'], ['harvey', 'houston'], ['rt', '.AT_USER', 'trump🇺🇸', 'amp', 'seemed', 'hopeless', '...', 'brought', 'hope', 'inspire', 'us', 'maga', 'harvey', 'usa…'], ['rt', 'kitty', 'flooded', 'harvey', 'cats', 'barely', 'rescued', 'please', 'help']]\n"
     ]
    }
   ],
   "source": [
    "print(ppTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Extract features from both training and test data using multinomial Naive Bayes Classifier\n",
    "\n",
    "#Step 4a : Build a Vocabulary\n",
    "\n",
    "#Step 4b : Represent each tweet with presence/absence of the relief terms in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5: Train the classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6 : Use the classifier to classify the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 7 : Model Inference & Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
